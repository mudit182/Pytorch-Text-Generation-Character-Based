{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"DAn5vQy9v4Tj","executionInfo":{"status":"ok","timestamp":1693588922018,"user_tz":-330,"elapsed":5628,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import numpy as np\n","\n","from collections import Counter"]},{"cell_type":"code","source":["import os\n","print(os.listdir())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mueq8Yy_wFxi","executionInfo":{"status":"ok","timestamp":1693588922020,"user_tz":-330,"elapsed":69,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}},"outputId":"5978f6c6-a32d-4414-fe11-83dd04faee66"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["['.config', 'sample_data']\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7mWIFrHyv4To","executionInfo":{"status":"ok","timestamp":1693588922061,"user_tz":-330,"elapsed":105,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}},"outputId":"708ffada-5dd8-4eef-f80e-f7f88b279629"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.autograd.anomaly_mode.set_detect_anomaly at 0x79b0dda56890>"]},"metadata":{},"execution_count":3}],"source":["# Enable anomaly detection during gradient computations,\n","# which helps in finding errors or unexpected behavior in your code\n","# related to gradients such as during training backprop\n","torch.autograd.set_detect_anomaly(True)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"7BV0SJdvv4Tq","executionInfo":{"status":"ok","timestamp":1693588922063,"user_tz":-330,"elapsed":94,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}}},"outputs":[],"source":["batch_size = 64\n","seq_size = 100\n","embedding_size = 256\n","lstm_size = 248\n","rnn_size=1024\n","gradients_norm = 5\n","# set device parameter\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","source":["torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FX3ZoYwWyBad","executionInfo":{"status":"ok","timestamp":1693588922066,"user_tz":-330,"elapsed":96,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}},"outputId":"bde6b924-042f-4838-ee91-c35a1ef8500f"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# Useful during multiple runs\n","# Clear gpu memory\n","if device == 'cuda':\n","  torch.cuda.empty_cache()"],"metadata":{"id":"CesGfNb6_9GP","executionInfo":{"status":"ok","timestamp":1693588922066,"user_tz":-330,"elapsed":69,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"id":"md05jhn2v4Tr","executionInfo":{"status":"ok","timestamp":1693588922067,"user_tz":-330,"elapsed":66,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}}},"outputs":[],"source":["# # read document\n","# with open('./sri_aurobindo_all_lines_final.txt', 'r') as f:\n","#     text = f.read()"]},{"cell_type":"code","source":["import tensorflow as tf\n","path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n","text = open(path_to_file, 'rb').read().decode(encoding='utf-8')"],"metadata":{"id":"6ch0IUk4O9pZ","executionInfo":{"status":"ok","timestamp":1693588926528,"user_tz":-330,"elapsed":4526,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bbfb0999-b6b9-40de-a844-60e31db07d5a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n","1115394/1115394 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1xml0ERqv4Ts","executionInfo":{"status":"ok","timestamp":1693588926529,"user_tz":-330,"elapsed":21,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}},"outputId":"2e9aee86-a221-42b7-8378-8efa620074ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Num of chars:  65\n"]}],"source":["vocab = sorted(set(text))\n","print('Num of chars: ', len(vocab))"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"24G9cV5Rv4Ts","executionInfo":{"status":"ok","timestamp":1693588926529,"user_tz":-330,"elapsed":18,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}}},"outputs":[],"source":["def vocab_map(chars_list):\n","    char_to_int = {c:i for i,c in enumerate(vocab)}\n","    int_to_char = {i:c for c,i in char_to_int.items()}\n","    return char_to_int, int_to_char\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"mOd0Z8Osv4Tt","executionInfo":{"status":"ok","timestamp":1693588926530,"user_tz":-330,"elapsed":18,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}}},"outputs":[],"source":["c_to_i, i_to_c = vocab_map(vocab)\n","\n","def ids_from_chars(chars: str):\n","  return [c_to_i[c] for c in chars]\n","\n","def chars_from_ids(ids):\n","  return ''.join([i_to_c[i] for i in ids])\n"]},{"cell_type":"code","source":["sample_seq = \"hello\"\n","print('sample: ', sample_seq)\n","sample_seq_int = ids_from_chars(sample_seq)\n","print('ids from chars: ', sample_seq_int)\n","sample_seq_char = chars_from_ids(sample_seq_int)\n","print('chars from ids: ', sample_seq_char)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JXHt2Ksn7PFH","executionInfo":{"status":"ok","timestamp":1693588926530,"user_tz":-330,"elapsed":18,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}},"outputId":"4c01e6de-2da7-4d2c-da68-b6bde6c52a70"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["sample:  hello\n","ids from chars:  [46, 43, 50, 50, 53]\n","chars from ids:  hello\n"]}]},{"cell_type":"code","execution_count":13,"metadata":{"id":"kU1YfCkwv4Tu","executionInfo":{"status":"ok","timestamp":1693588926530,"user_tz":-330,"elapsed":16,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}}},"outputs":[],"source":["def get_batches(full_text, ids_from_chars, batch_size, seq_size):\n","    # generate Xs and Ys of shape (batch_size * num_batches) * seq_size\n","    text_vectorized = ids_from_chars(full_text)\n","    num_batches = int(len(text_vectorized) / (batch_size * seq_size))\n","    Xs = text_vectorized[:num_batches*batch_size*seq_size]\n","    Ys = np.zeros_like(Xs)\n","    Ys[:-1] = Xs[1:]\n","    Ys[-1] = Xs[0] if len(Xs) == len(text_vectorized) else text_vectorized[len(Xs)]\n","    Xs = np.reshape(Xs, (num_batches*batch_size, seq_size))\n","    Ys= np.reshape(Ys, (num_batches*batch_size, seq_size))\n","\n","    # iterate over rows of Xs and Ys to generate batches\n","    for i in range(0, num_batches*batch_size, batch_size):\n","        yield Xs[i:i+batch_size, :], Ys[i:i+batch_size, :]"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"L4DfD1lOv4Tv","executionInfo":{"status":"ok","timestamp":1693588926531,"user_tz":-330,"elapsed":16,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}}},"outputs":[],"source":["data_gen = get_batches(text, ids_from_chars, batch_size, seq_size)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B840DczAv4Tv","executionInfo":{"status":"ok","timestamp":1693588926531,"user_tz":-330,"elapsed":16,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}},"outputId":"12663192-70ea-478c-a468-5cefc27b80ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["X shape:  (64, 100) Y shape:  (64, 100)\n"]}],"source":["X,Y = next(data_gen)\n","print('X shape: ', X.shape, 'Y shape: ', Y.shape)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"fN7BPQnXv4Tw","executionInfo":{"status":"ok","timestamp":1693588926532,"user_tz":-330,"elapsed":14,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}}},"outputs":[],"source":["class RNNModule(nn.Module):\n","    # initialize RNN module\n","    def __init__(self, n_vocab, seq_size=100, embedding_size=64, rnn_size=1024):\n","        super(RNNModule, self).__init__()\n","        self.seq_size = seq_size\n","        self.rnn_size = rnn_size\n","        self.embedding = nn.Embedding(n_vocab, embedding_size)\n","        self.rnn = nn.GRU(embedding_size,\n","                            rnn_size,\n","                            batch_first=True)\n","        self.dense = nn.Linear(rnn_size, n_vocab)\n","\n","    def forward(self, x, prev_state):\n","        embed = self.embedding(x)\n","        output, state = self.rnn(embed, prev_state)\n","        logits = self.dense(output)\n","\n","        return logits, state\n","\n","    def zero_state(self, batch_size):\n","        return torch.zeros(1, batch_size, self.rnn_size)\n"]},{"cell_type":"code","source":["class LSTMModule(nn.Module):\n","    # initialize LSTM module\n","    def __init__(self, n_vocab, seq_size=100, embedding_size=64, lstm_size=248):\n","        super(LSTMModule, self).__init__()\n","        self.seq_size = seq_size\n","        self.lstm_size = lstm_size\n","        self.embedding = nn.Embedding(n_vocab, embedding_size)\n","        self.lstm = nn.LSTM(embedding_size,\n","                            lstm_size,\n","                            batch_first=True)\n","        self.dense = nn.Linear(lstm_size, n_vocab)\n","\n","    def forward(self, x, prev_state):\n","        embed = self.embedding(x)\n","        output, state = self.lstm(embed, prev_state)\n","        logits = self.dense(output)\n","\n","        return logits, state\n","\n","    def zero_state(self, batch_size):\n","        return (torch.zeros(1, batch_size, self.lstm_size), torch.zeros(1, batch_size, self.lstm_size))"],"metadata":{"id":"v6WKpKrAuT1U","executionInfo":{"status":"ok","timestamp":1693588926532,"user_tz":-330,"elapsed":14,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","execution_count":18,"metadata":{"id":"4xvYqx7uv4Tx","executionInfo":{"status":"ok","timestamp":1693588926532,"user_tz":-330,"elapsed":13,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}}},"outputs":[],"source":["def get_loss_and_train_op(net, lr=0.001):\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n","\n","    return criterion, optimizer"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"51ISiwg0v4Tx","executionInfo":{"status":"ok","timestamp":1693588939868,"user_tz":-330,"elapsed":13348,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}},"outputId":"42509a83-80a6-4db8-fe39-a6474dd8e170"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["LSTMModule(\n","  (embedding): Embedding(65, 256)\n","  (lstm): LSTM(256, 248, batch_first=True)\n","  (dense): Linear(in_features=248, out_features=65, bias=True)\n",")"]},"metadata":{},"execution_count":19}],"source":["# net = RNNModule(len(vocab), seq_size, embedding_size, rnn_size) # rnn\n","net = LSTMModule(len(vocab), seq_size, embedding_size, lstm_size) # lstm\n","net = net.to(device)\n","net"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HUNin0NCv4Ty","executionInfo":{"status":"ok","timestamp":1693588941591,"user_tz":-330,"elapsed":1726,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}},"outputId":"ecb14f69-98fd-471e-a956-ade3752ba648"},"outputs":[{"output_type":"stream","name":"stdout","text":["Net output shape:  torch.Size([64, 100, 65]) Expected Y shape:  torch.Size([64, 100])\n","Loss =  4.156425952911377\n"]}],"source":["\n","# state = net.zero_state(batch_size) # rnn\n","state_h, state_c = net.zero_state(batch_size) # lstm\n","\n","# Transfer data to GPU\n","# state = state.to(device) # rnn\n","state_h = state_h.to(device) # lstm\n","state_c = state_c.to(device) # lstm\n","\n","\n","X_inp, Y_inp = next(data_gen)\n","X_inp = torch.tensor(X_inp).to(device)\n","Y_inp = torch.tensor(Y_inp).to(device)\n","\n","\n","# logits, state = net(X_inp, state) # rnn\n","logits, (state_h, state_c) = net(X_inp, (state_h, state_c)) # lstm\n","\n","# Note cross entropy expects\n","print('Net output shape: ', logits.shape, 'Expected Y shape: ', Y_inp.shape)\n","\n","criterion, optimizer = get_loss_and_train_op(net)\n","loss = criterion(logits.transpose(1, 2), Y_inp)\n","print('Loss = ', loss.item())\n"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"r2rR9tfwv4Tz","executionInfo":{"status":"ok","timestamp":1693588941592,"user_tz":-330,"elapsed":8,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}}},"outputs":[],"source":["def train_model(full_text, ids_from_chars, n_vocab):\n","\n","    # model instance\n","    # net = RNNModule(n_vocab, seq_size, embedding_size, rnn_size) # rnn\n","    net = LSTMModule(len(vocab), seq_size, embedding_size, lstm_size) # lstm\n","    net = net.to(device)\n","    criterion, optimizer = get_loss_and_train_op(net, 0.001)\n","\n","    num_batches = int(len(full_text) / (batch_size * seq_size))\n","\n","    epochs = 20\n","    for e in range(epochs):\n","        iteration = 0\n","        batches = get_batches(full_text, ids_from_chars, batch_size, seq_size)\n","        # state = net.zero_state(batch_size) # rnn\n","        state_h, state_c = net.zero_state(batch_size) # lstm\n","\n","        # Transfer data to GPU\n","        # state = state.to(device) # rnn\n","        state_h = state_h.to(device) # lstm\n","        state_c = state_c.to(device) # lstm\n","\n","        for x, y in batches:\n","            # Tell it we are in training mode\n","            net.train()\n","\n","            # Reset all gradients\n","            optimizer.zero_grad()\n","\n","            # Transfer data to GPU\n","            x = torch.tensor(x).to(device)\n","            y = torch.tensor(y).to(device)\n","\n","            # logits, state = net(x, state) # rnn\n","            logits, (state_h, state_c) = net(x, (state_h, state_c)) # lstm\n","\n","            loss = criterion(logits.transpose(1, 2), y)\n","\n","            state_h = state_h.detach() # lstm\n","            state_c = state_c.detach() # lstm\n","            # state = state.detach() # rnn\n","\n","            loss_value = loss.item()\n","\n","            # Perform back-propagation\n","            loss.backward(retain_graph=True)\n","\n","            _ = torch.nn.utils.clip_grad_norm_(net.parameters(), gradients_norm)\n","\n","            # Update the network's parameters\n","            optimizer.step()\n","\n","            if iteration % 100 == 0:\n","                print(f'Epoch: {e}/{epochs} Iteration: {iteration}/{num_batches} Loss: {loss_value}')\n","            iteration += 1\n","\n","    return net"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vcbtx5iav4T0","executionInfo":{"status":"ok","timestamp":1693588991489,"user_tz":-330,"elapsed":49903,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}},"outputId":"514d2a32-8fcf-4673-da26-2c37996eaf13"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0/20 Iteration: 0/174 Loss: 4.176697254180908\n","Epoch: 0/20 Iteration: 100/174 Loss: 2.1926980018615723\n","Epoch: 1/20 Iteration: 0/174 Loss: 2.1061949729919434\n","Epoch: 1/20 Iteration: 100/174 Loss: 1.8128465414047241\n","Epoch: 2/20 Iteration: 0/174 Loss: 1.8983770608901978\n","Epoch: 2/20 Iteration: 100/174 Loss: 1.640510082244873\n","Epoch: 3/20 Iteration: 0/174 Loss: 1.768168330192566\n","Epoch: 3/20 Iteration: 100/174 Loss: 1.5331469774246216\n","Epoch: 4/20 Iteration: 0/174 Loss: 1.6858881711959839\n","Epoch: 4/20 Iteration: 100/174 Loss: 1.4579989910125732\n","Epoch: 5/20 Iteration: 0/174 Loss: 1.6302502155303955\n","Epoch: 5/20 Iteration: 100/174 Loss: 1.404670000076294\n","Epoch: 6/20 Iteration: 0/174 Loss: 1.5886951684951782\n","Epoch: 6/20 Iteration: 100/174 Loss: 1.3629822731018066\n","Epoch: 7/20 Iteration: 0/174 Loss: 1.5567364692687988\n","Epoch: 7/20 Iteration: 100/174 Loss: 1.3273605108261108\n","Epoch: 8/20 Iteration: 0/174 Loss: 1.5302850008010864\n","Epoch: 8/20 Iteration: 100/174 Loss: 1.300691843032837\n","Epoch: 9/20 Iteration: 0/174 Loss: 1.5071275234222412\n","Epoch: 9/20 Iteration: 100/174 Loss: 1.2807018756866455\n","Epoch: 10/20 Iteration: 0/174 Loss: 1.4881904125213623\n","Epoch: 10/20 Iteration: 100/174 Loss: 1.265447735786438\n","Epoch: 11/20 Iteration: 0/174 Loss: 1.4726260900497437\n","Epoch: 11/20 Iteration: 100/174 Loss: 1.2500319480895996\n","Epoch: 12/20 Iteration: 0/174 Loss: 1.4586880207061768\n","Epoch: 12/20 Iteration: 100/174 Loss: 1.240331768989563\n","Epoch: 13/20 Iteration: 0/174 Loss: 1.4463660717010498\n","Epoch: 13/20 Iteration: 100/174 Loss: 1.229000449180603\n","Epoch: 14/20 Iteration: 0/174 Loss: 1.43671452999115\n","Epoch: 14/20 Iteration: 100/174 Loss: 1.2182003259658813\n","Epoch: 15/20 Iteration: 0/174 Loss: 1.4275859594345093\n","Epoch: 15/20 Iteration: 100/174 Loss: 1.210594892501831\n","Epoch: 16/20 Iteration: 0/174 Loss: 1.4199756383895874\n","Epoch: 16/20 Iteration: 100/174 Loss: 1.2039841413497925\n","Epoch: 17/20 Iteration: 0/174 Loss: 1.4126092195510864\n","Epoch: 17/20 Iteration: 100/174 Loss: 1.1966509819030762\n","Epoch: 18/20 Iteration: 0/174 Loss: 1.4030495882034302\n","Epoch: 18/20 Iteration: 100/174 Loss: 1.1912986040115356\n","Epoch: 19/20 Iteration: 0/174 Loss: 1.3958739042282104\n","Epoch: 19/20 Iteration: 100/174 Loss: 1.1853374242782593\n"]}],"source":["# rnn_net = train_model(text, ids_from_chars, len(vocab))\n","lstm_net = train_model(text, ids_from_chars, len(vocab))"]},{"cell_type":"code","source":["def one_step(net, ix, state, temperature = 1):\n","  output, state = net(ix, state)\n","\n","  last_predicted_char_output = output[:,-1]\n","  scaled_chars_probs = last_predicted_char_output / temperature\n","\n","  chars_probs = F.softmax(scaled_chars_probs, dim=-1)\n","  predicted_ids = torch.multinomial(chars_probs, num_samples=1).squeeze(-1)\n","\n","  predicted_ids = predicted_ids.tolist()\n","  next_chars = [chars_from_ids([id]) for id in predicted_ids]\n","\n","  return next_chars, state"],"metadata":{"id":"i8N7a0TPCgpn","executionInfo":{"status":"ok","timestamp":1693588991490,"user_tz":-330,"elapsed":12,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","execution_count":27,"metadata":{"id":"9bExjWhWv4T1","executionInfo":{"status":"ok","timestamp":1693589122289,"user_tz":-330,"elapsed":472,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}}},"outputs":[],"source":["def generate_text(net, start_text, temperature=1):\n","    net.eval()\n","\n","    ix = torch.tensor([ids_from_chars(start_text)])\n","    ix = ix.to(device)\n","    # state = net.zero_state(len(ix)) # rnn\n","    # state = state.to(device) # rnn\n","    state_h, state_c = net.zero_state(len(ix)) # lstm\n","\n","    state_h = state_h.to(device) # lstm\n","    state_c = state_c.to(device) # lstm\n","    state = (state_h, state_c)\n","\n","    final_text = start_text\n","\n","    for i in range(1000):\n","      next_chars, state = one_step(net, ix, state, temperature=temperature)\n","      ix = torch.tensor([ids_from_chars(next_chars)])\n","      ix = ix.to(device)\n","      final_text += next_chars[0]\n","\n","    return final_text"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"M7J_oDMPv4T3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693589129302,"user_tz":-330,"elapsed":5182,"user":{"displayName":"Mudit Gurjar","userId":"10940562116634188279"}},"outputId":"eba22d32-5654-4199-b140-87be6d72899b"},"outputs":[{"output_type":"stream","name":"stdout","text":["What beholds a fair;\n","And brain to they by Juliet,\n","Hark'd the prize and the pray save:\n"," master's Kate in our twother's honour\n","Than twice as treys and drankly is lay ends begin.\n","\n","BIONDELLO:\n","Thus brother chantently one this,\n","Did content a sclived Ned.'\n","Duke and now and hundred friend:\n","I have actsemituty,\n","And mad up.\n","\n","BIONDA:\n","Bovereive, if say me made a createnting;\n","While from sure?\n","I provock the other noble and reaso\n","To quapting off it, at Biancais' the sister,\n","If not.\n","After his, earny thourd on\n","the good many colled: joy my husband,\n","And pare ta'en shrewd: as please me.\n","The entreat but\n","For fire, know you within the treawd Lord for ever light.\n","Most lord! what!' the return that his gazed:\n","I loves it.\n","\n","PROSPERO:\n","Then, thought that hoouse trueldnemanuman!\n","\n","POMPEY:\n","I master, but fasher. Pray my tauty!\n","\n","VALUMINIUS:\n","Ay, if his partaintly. King with all,\n","And dost.\n","\n","MIRANDA:\n","Some vaitor such daughtrongum.\n","Nay, lost they are men shall know?\n","\n","ISABELLA:\n","And so it she is for an immstand-heard dinarly dimpleeding.\n","\n","CAMILL\n"]}],"source":["print(generate_text(lstm_net, \"What beholds a fair\"))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"orig_nbformat":4,"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}